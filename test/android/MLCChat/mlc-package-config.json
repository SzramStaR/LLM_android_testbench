{
    "device": "android",
    "model_list": [
        {
            "model": "HF://mlc-ai/Llama-3.2-3B-Instruct-q0f32-MLC",
            "model_id": "Llama-3.2-3B-Instruct-q0f32-MLC",
            "estimated_vram_bytes": 4679979417,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.2-3B-Instruct-q4f32_1-MLC",
            "model_id": "Llama-3.2-3B-Instruct-q4f32_1-MLC",
            "estimated_vram_bytes": 4679979417,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.2-3B-Instruct-q0f16-MLC",
            "model_id": "Llama-3.2-3B-Instruct-q0f16-MLC",
            "estimated_vram_bytes": 4679979417,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.2-3B-Instruct-q4f16_1-MLC",
            "model_id": "Llama-3.2-3B-Instruct-q4f16_1-MLC",
            "estimated_vram_bytes": 4679979417,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.2-3B-Instruct-q4f16_0-MLC",
            "estimated_vram_bytes": 4679979417,
            "model_id": "Llama-3.2-3B-Instruct-q4f16_0-MLC",
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.1-8B-Instruct-q3f16_1-MLC",
            "model_id": "Llama-3.1-8B-Instruct-q3f16_1-MLC",
            "estimated_vram_bytes": 8000000000,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.1-8B-Instruct-q0f16-MLC",
            "model_id": "Llama-3.1-8B-Instruct-q0f16-MLC",
            "estimated_vram_bytes": 8000000000,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.1-8B-Instruct-q4f16_1-MLC",
            "model_id": "Llama-3.1-8B-Instruct-q4f16_1-MLC",
            "estimated_vram_bytes": 8000000000,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.1-8B-Instruct-q4f32_1-MLC",
            "model_id": "Llama-3.1-8B-Instruct-q4f32_1-MLC",
            "estimated_vram_bytes": 8000000000,
            "overrides": {
                "context_window_size": 4096
            }
        },
        {
            "model": "HF://mlc-ai/Llama-3.1-8B-Instruct-q3f16_0-MLC",
            "model_id": "Llama-3.1-8B-Instruct-q3f16_0-MLC",
            "estimated_vram_bytes": 8000000000,
            "overrides": {
                "context_window_size": 4096
            }
        }
    ]
}
